{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bob's Discount Furniture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warning: because some data products are inconsistent (changing JSON formats, etc...), not all code cleanly refactorable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "import xspec_utils as xs\n",
    "from nice_tables import LatexTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fd = xs.load_dict(\"results_spec/20160701_fiveann.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Soft proton parameters as a function of radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "latex_hdr = [['Annulus', '2001 MOS', '2001 PN', '2009 MOS']]\n",
    "latex_cols = ['{:s}', 0, 0, 0]\n",
    "ltab = LatexTable(latex_hdr, latex_cols, \"Soft proton power law indices\", prec=2)\n",
    "\n",
    "labels = ['0-100', '100-200', '200-300', '300-400', '400-500']\n",
    "spectra = [np.array([1,3,5]),\n",
    "           np.array([1,3,5]) + 5,\n",
    "           np.array([1,3,5]) + 10,\n",
    "           np.array([1,3,5]) + 15,\n",
    "           np.array([1,3,5]) + 20]\n",
    "spectra = [map(str, x) for x in spectra]\n",
    "\n",
    "for lab, indices in zip(labels, spectra):\n",
    "    ltr = [lab]\n",
    "    for idx in indices:\n",
    "        ltr.append(fd[idx]['sp']['powerlaw']['PhoIndex']['value'])\n",
    "    ltab.add_row(*ltr)\n",
    "\n",
    "print ltab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hard to see for 0087940201 MOS1 case, but 200-300 powerlaw basically overlaps 400-500.\n",
    "Behavior is broadly consistent with what we expect, actually, which is very reassuring.  Fits also get jumpier going outwards in radius.  But, outer annuli encompass larger annuli -- so the counts should still be pretty comparable.  I would actually expect outer annuli fits to be a bit better constrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = np.logspace(-1, 1)\n",
    "\n",
    "for offset, exposure in enumerate(['0087940201 MOS1', '0087940201 MOS2', '0087940201 PN',\n",
    "                                   '0551000201 MOS1','0551000201 MOS2']):\n",
    "    print exposure\n",
    "    for idx, lab in zip(np.array([1, 6, 11, 16, 21]) + offset,\n",
    "                        ['0-100', '100-200', '200-300', '300-400', '400-500']):\n",
    "        idx = str(idx)\n",
    "        phoindex = fd[idx]['sp']['powerlaw']['PhoIndex']['value']\n",
    "        norm = fd[idx]['sp']['powerlaw']['norm']['value']\n",
    "        print \"{:s}: index {:.2f}, norm {:.2e}\".format(lab, phoindex, norm)\n",
    "        plt.loglog(x, norm * x**(-1 * phoindex), label=lab)\n",
    "\n",
    "    plt.legend(loc='best')\n",
    "    plt.xlabel(\"Energy (keV)\")\n",
    "    plt.ylabel(r'Effective photons s$^{-1}$ cm$^{-2}$ keV$^{-1}$')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vnei fit parameters as a function of radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fd = xs.load_dict(\"results_spec/20160701_fiveann.json\")\n",
    "vals = []\n",
    "p_errs = []\n",
    "n_errs = []\n",
    "for idx, model in zip(np.array([1, 6, 11, 16, 21]),\n",
    "                  ['snr_ann_000_100', 'snr_ann_100_200', 'snr_ann_200_300', 'snr_ann_300_400', 'snr_ann_400_500']):\n",
    "    c = fd[str(idx)][model]['vnei']['kT']\n",
    "    vals.append(c['value'])\n",
    "    p_errs.append(c['error'][1] - c['value'])\n",
    "    n_errs.append(abs(c['error'][0] - c['value']))\n",
    "plt.errorbar([50, 150, 250, 350, 450], vals, yerr=[n_errs, p_errs], xerr=50, marker='o', ls='', label='5')\n",
    "\n",
    "fd = xs.load_dict(\"results_spec/20160708_fourann_center-mg-o-free.json\")\n",
    "vals = []\n",
    "p_errs = []\n",
    "n_errs = []\n",
    "for idx, model in zip(np.array([1, 6, 11, 16]),\n",
    "                  ['snr_ann_000_100', 'snr_ann_100_200', 'snr_ann_200_300', 'snr_ann_300_400']):\n",
    "    c = fd[str(idx)][model]['vnei']['kT']\n",
    "    vals.append(c['value'])\n",
    "    p_errs.append(c['error'][1] - c['value'])\n",
    "    n_errs.append(abs(c['error'][0] - c['value']))\n",
    "plt.errorbar([48, 148, 248, 348], vals, yerr=[n_errs, p_errs], xerr=50, marker='o', ls='', label='4Mg,O')\n",
    "\n",
    "fd = xs.load_dict(\"results_spec/20160708_fourann_center-mg-fe-free.json\")\n",
    "vals = []\n",
    "p_errs = []\n",
    "n_errs = []\n",
    "for idx, model in zip(np.array([1, 6, 11, 16]),\n",
    "                  ['snr_ann_000_100', 'snr_ann_100_200', 'snr_ann_200_300', 'snr_ann_300_400']):\n",
    "    c = fd[str(idx)][model]['vnei']['kT']\n",
    "    vals.append(c['value'])\n",
    "    p_errs.append(c['error'][1] - c['value'])\n",
    "    n_errs.append(abs(c['error'][0] - c['value']))\n",
    "plt.errorbar([52, 152, 252, 352], vals, yerr=[n_errs, p_errs], xerr=50, marker='o', ls='', label='4Mg,Fe')\n",
    "\n",
    "fd = xs.load_dict(\"results_spec/20160708_fourann_center-mg-o-ne-free.json\")\n",
    "vals = []\n",
    "p_errs = []\n",
    "n_errs = []\n",
    "for idx, model in zip(np.array([1, 6, 11, 16]),\n",
    "                  ['snr_ann_000_100', 'snr_ann_100_200', 'snr_ann_200_300', 'snr_ann_300_400']):\n",
    "    c = fd[str(idx)][model]['vnei']['kT']\n",
    "    vals.append(c['value'])\n",
    "    p_errs.append(c['error'][1] - c['value'])\n",
    "    n_errs.append(abs(c['error'][0] - c['value']))\n",
    "plt.errorbar([51, 151, 251, 351], vals, yerr=[n_errs, p_errs], xerr=50, marker='o', ls='', label='4Mg,O,Ne')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(\"Radius (arcseconds)\")\n",
    "plt.ylabel(r'Plasma electron temperature (keV)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source fit parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todo: just regenerate all the joint source-background fits with new products.\n",
    "Saves fair bit of trouble, should be straightforward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Four annuli with varied center abundances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fdictfs = [\"results_spec/20160708_fourann_center-mg-free_snr_ann_000_100.json\",\n",
    "          \"results_spec/20160708_fourann_center-mg-o-free_snr_ann_000_100.json\",\n",
    "          \"results_spec/20160708_fourann_center-mg-ne-free_snr_ann_000_100.json\",\n",
    "          \"results_spec/20160708_fourann_center-mg-o-ne-free_snr_ann_000_100.json\",\n",
    "          \"results_spec/20160708_fourann_center-mg-fe-free_snr_ann_000_100.json\",\n",
    "          \"results_spec/20160712_fourann_center-mg-o-fe-free.json\"\n",
    "          ]\n",
    "# fdictf = fit dict file\n",
    "labels = [\"4Mg\", \"4Mg,O\", \"4Mg,Ne\", \"4Mg,Ne,O\", \"4Mg,Fe\", \"4Mg,O,Fe\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def val_pnerrs(fit_dict, model, comp, old=False):\n",
    "    \"\"\"Convenience method to extract\n",
    "    value, +ve error, -ve error\n",
    "    from a fit_dict.  Errors are signed (i.e., -ve error value is < 0)\n",
    "    \n",
    "    AS CONSTRUCTED ONLY OPERATES ON FIRST SPECTRUM (hack) for non-\"old\" dicts\n",
    "    \n",
    "    Arguments\n",
    "        fit_dict: xspec_utils fit dict (i.e., JSON dict)\n",
    "        model: model name (string)\n",
    "        comp: component name (string)\n",
    "    Returns:\n",
    "        value, +ve error, -ve error three-tuple\n",
    "    \"\"\"\n",
    "    if not old:\n",
    "        c = fit_dict[\"1\"][\"snr_ann_000_100\"][model][comp]\n",
    "    else:\n",
    "        c = fit_dict['comps'][model][comp]\n",
    "    val = c['value']\n",
    "    pos_err = c['error'][1] - c['value']\n",
    "    neg_err = c['error'][0] - c['value']\n",
    "    return val, pos_err, neg_err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "latex_hdr = [['Annulus', ''],\n",
    "             [r'$n_\\mathrm{H}$', r'($10^{22} \\unit{cm^{-2}}$)'],\n",
    "             [r'$kT$', r'(keV)'],\n",
    "             [r'$\\tau$', r'($10^{10} \\unit{s\\;cm^{-3}}$)'],\n",
    "             ['O', '(-)'],\n",
    "             ['Ne', '(-)'],\n",
    "             ['Mg', '(-)'],\n",
    "             ['Si', '(-)'],\n",
    "             ['S', '(-)'],\n",
    "             ['Fe', '(-)'],\n",
    "             [r'$\\chi^2_{\\mt{red}}$', r'$\\chi^2 / (\\mt{dof})$']]\n",
    "latex_hdr = np.array(latex_hdr).T\n",
    "\n",
    "latex_cols = ['{:s}', 2, 2, 2, 2, 2] + 4 * [2] + ['{:s}']  # O, Ne, Mg, Fe; chisqred\n",
    "ltab = LatexTable(latex_hdr, latex_cols, \"G309.2-0.6 annuli fit with errors\", prec=2)\n",
    "\n",
    "for fdictf, lab in zip(fdictfs, labels):\n",
    "    \n",
    "    fd = xs.load_dict(fdictf)\n",
    "    old = \"20160708\" in fdictf\n",
    "    \n",
    "    ltr = [lab]\n",
    "    ltr.extend(val_pnerrs(fd, 'tbnew_gas', 'nH', old=old))\n",
    "    ltr.extend(val_pnerrs(fd, 'vnei', 'kT', old=old))\n",
    "    ltr.extend(np.array(val_pnerrs(fd, 'vnei', 'Tau', old=old)) / 1e10)\n",
    "    ltr.extend(val_pnerrs(fd, 'vnei', 'O', old=old))\n",
    "    ltr.extend(val_pnerrs(fd, 'vnei', 'Ne', old=old))\n",
    "    ltr.extend(val_pnerrs(fd, 'vnei', 'Mg', old=old))\n",
    "    ltr.extend(val_pnerrs(fd, 'vnei', 'Si', old=old))\n",
    "    ltr.extend(val_pnerrs(fd, 'vnei', 'S', old=old))\n",
    "    ltr.extend(val_pnerrs(fd, 'vnei', 'Fe', old=old))\n",
    "    \n",
    "    if old:\n",
    "        ltr.append(\"{:.3f} = {:.2f} / {:d}\".format(fd['fitstat'][1] / fd['dof'], fd['fitstat'][1], fd['dof']))\n",
    "    else:\n",
    "        ltr.append(\"{:.3f} = {:.2f} / {:d}\".format(fd['fitStat'] / fd['dof'], fd['fitStat'], fd['dof']))\n",
    "\n",
    "    ltab.add_row(*ltr)\n",
    "\n",
    "print ltab.__str__().replace('${1.00}^{-1.00}_{-1.00}$', '    ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabulate annulus fit parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Nice LaTeX table\n",
    "\n",
    "fd = xs.load_dict(\"results_spec/20160701_fiveann.json\")\n",
    "rings = []\n",
    "for idx, model in zip([1, 6, 11, 16, 21], ['snr_ann_000_100', 'snr_ann_100_200',\n",
    "                                           'snr_ann_200_300', 'snr_ann_300_400', 'snr_ann_400_500']):\n",
    "    rings.append(fd[str(idx)][model])\n",
    "\n",
    "def ring_val_errs(ring, cname, pname):\n",
    "    p = ring[cname][pname]\n",
    "    val = p['value']\n",
    "    pos_err = p['error'][1] - p['value']\n",
    "    neg_err = p['error'][0] - p['value']\n",
    "    return val, pos_err, neg_err\n",
    "\n",
    "latex_hdr = [['Annulus', ''],\n",
    "             [r'$n_\\mathrm{H}$', r'($10^{22} \\unit{cm^{-2}}$)'],\n",
    "             [r'$kT$', r'(keV)'],\n",
    "             [r'$\\tau$', r'($10^{10} \\unit{s\\;cm^{-3}}$)'],\n",
    "             ['Si', '(-)'],\n",
    "             ['S', '(-)']]\n",
    "latex_hdr = np.array(latex_hdr).T\n",
    "\n",
    "latex_cols = ['{:s}', 2, 2, 2, 2, 2]\n",
    "ltab = LatexTable(latex_hdr, latex_cols, \"G309.2-0.6 annuli fit with errors\", prec=2)\n",
    "\n",
    "for ring in rings:\n",
    "    ltr = [ring['name']]\n",
    "    ltr.extend(ring_val_errs(ring, 'tbnew_gas', 'nH'))\n",
    "    ltr.extend(ring_val_errs(ring, 'vnei', 'kT'))\n",
    "    ltr.extend(np.array(ring_val_errs(ring, 'vnei', 'Tau')) / 1e10)\n",
    "    ltr.extend(ring_val_errs(ring, 'vnei', 'Si'))\n",
    "    ltr.extend(ring_val_errs(ring, 'vnei', 'S'))\n",
    "\n",
    "    ltab.add_row(*ltr)\n",
    "\n",
    "print ltab"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
